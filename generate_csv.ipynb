{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip, random, string, csv\n",
    "from pathlib import Path\n",
    "\n",
    "GiB = 1024 ** 3\n",
    "PATTERN = (\"loremIPSUM0123456789_-\" * 20)\n",
    "\n",
    "def make_payload(length: int) -> str:\n",
    "    if length <= 0:\n",
    "        return \"\"\n",
    "    s = (PATTERN * ((length // len(PATTERN)) + 1))[:length]\n",
    "    return s\n",
    "\n",
    "def write_csv_until_size(path: Path, target_bytes: int, *, with_header: bool = True,\n",
    "                         payload_len: int = 128, progress_mb: int = 256, seed: int = 42) -> None:\n",
    "    rng = random.Random(seed)\n",
    "    categories = [f\"cat{c}\" for c in range(1, 1001)]\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    written_last_report = 0\n",
    "    with path.open(\"w\", newline='', encoding=\"utf-8\") as f:\n",
    "        w = csv.writer(f)\n",
    "        if with_header:\n",
    "            w.writerow([\"id\",\"category\",\"payload\"])\n",
    "        i = 0\n",
    "        while True:\n",
    "            i += 1\n",
    "            cat = rng.choice(categories)\n",
    "            payload = make_payload(payload_len)\n",
    "            w.writerow([i, cat, payload])\n",
    "\n",
    "            pos = f.tell()\n",
    "            if pos - written_last_report >= progress_mb * 1024 * 1024:\n",
    "                written_last_report = pos\n",
    "                print(f\"[{path.name}] {pos/1024/1024:.1f} MiB escritos...\")\n",
    "\n",
    "            if pos >= target_bytes:\n",
    "                break\n",
    "\n",
    "    print(f\"Concluído: {path} ({path.stat().st_size/1024/1024:.2f} MiB)\")\n",
    "\n",
    "def shard_naming(base_out: Path, shard_idx: int) -> Path:\n",
    "    stem = base_out.stem if base_out.suffix else base_out.name\n",
    "    suffix = base_out.suffix if base_out.suffix.lower() == \".csv\" else \".csv\"\n",
    "    return base_out.with_name(f\"{stem}-{shard_idx:05d}{suffix}\")\n",
    "\n",
    "def generate_csv(out: Path, size_gb: float, with_header: bool = True,\n",
    "                     payload_len: int = 128, progress_mb: int = 256,\n",
    "                     seed: int = 42, n_shards: int = 1) -> None:\n",
    "    target_bytes_total = int(size_gb * GiB)\n",
    "    if n_shards <= 1:\n",
    "        write_csv_until_size(out, target_bytes_total, with_header=with_header,\n",
    "                             payload_len=payload_len, progress_mb=progress_mb, seed=seed)\n",
    "    else:\n",
    "        per_shard = target_bytes_total // n_shards\n",
    "        remainder = target_bytes_total % n_shards\n",
    "        print(f\"Escrevendo {n_shards} shards, ~{per_shard/1024/1024:.1f} MiB cada (+ resto {remainder} bytes).\")\n",
    "        for i in range(n_shards):\n",
    "            shard_target = per_shard + (remainder if i == n_shards - 1 else 0)\n",
    "            shard_path = shard_naming(out, i)\n",
    "            write_csv_until_size(shard_path, shard_target, with_header=with_header,\n",
    "                                 payload_len=payload_len, progress_mb=progress_mb, seed=seed + i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT_DIR = Path(\"./dados/base_200mb.csv\")\n",
    "SIZE_GB = 0.2\n",
    "\n",
    "N_SHARDS = 1\n",
    "WITH_HEADER = True\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "\n",
    "PAYLOAD_LEN = 128 # Define a quantidade de linhas do payload\n",
    "PROGRESS_MB = 128 # Limita o progresso a ser impresso na saída a cada X MiB (X = PROGRESS_MB)\n",
    "\n",
    "CONFIRM_LARGE = False # Confirma com True para permitir execuções com SIZE_GB >= 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Execução ===\n",
    "if SIZE_GB >= 1 and not CONFIRM_LARGE:\n",
    "    raise SystemExit(\"Ative CONFIRM_LARGE=True antes de gerar arquivos >= 1 GiB.\")\n",
    "\n",
    "generate_csv(OUT_DIR, SIZE_GB, with_header=WITH_HEADER, payload_len=PAYLOAD_LEN,\n",
    "                 progress_mb=PROGRESS_MB, seed=SEED, n_shards=N_SHARDS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import csv\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "STATES = [\"AC\",\"AL\",\"AP\",\"AM\",\"BA\",\"CE\",\"DF\",\"ES\",\"GO\",\"MA\",\"MT\",\"MS\",\"MG\",\"PA\",\"PB\",\"PR\",\"PE\",\"PI\",\"RJ\",\"RN\",\"RS\",\"RO\",\"RR\",\"SC\",\"SP\",\"SE\",\"TO\"]\n",
    "CATEGORIES = [f\"cat{c}\" for c in range(1, 501)]\n",
    "PATTERN = \"loremIPSUM0123456789_-\"\n",
    "\n",
    "def make_payload(length: int) -> str:\n",
    "    if length <= 0:\n",
    "        return \"\"\n",
    "    s = (PATTERN * ((length // len(PATTERN)) + 1))[:length]\n",
    "    return s\n",
    "\n",
    "def write_csv_header(path: Path, header):\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with path.open(\"w\", newline='', encoding=\"utf-8\") as f:\n",
    "        csv.writer(f).writerow(header)\n",
    "\n",
    "def append_row(path: Path, row):\n",
    "    with path.open(\"a\", newline='', encoding=\"utf-8\") as f:\n",
    "        csv.writer(f).writerow(row)\n",
    "\n",
    "def generate_bases(out_dir: Path, target_bytes: int, seed: int = 42,\n",
    "                   n_customers: int = 200_000, n_products: int = 100_000,\n",
    "                   avg_items_per_order: float = 3.0, payload_len: int = 64) -> None:\n",
    "    rng = random.Random(seed)\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    customers_p = out_dir / \"customers.csv\"\n",
    "    products_p = out_dir / \"products.csv\"\n",
    "    orders_p = out_dir / \"orders.csv\"\n",
    "    items_p = out_dir / \"order_items.csv\"\n",
    "    for p, header in [\n",
    "        (customers_p, [\"customer_id\",\"name\",\"email\",\"state\"]),\n",
    "        (products_p, [\"product_id\",\"category\",\"price_cents\"]),\n",
    "        (orders_p, [\"order_id\",\"customer_id\",\"order_ts\",\"order_total_cents\"]),\n",
    "        (items_p, [\"order_id\",\"product_id\",\"qty\",\"unit_price_cents\",\"line_total_cents\",\"payload\"]),\n",
    "    ]:\n",
    "        write_csv_header(p, header)\n",
    "\n",
    "    denorm_p = out_dir / \"denormalized.csv\"\n",
    "    with denorm_p.open(\"w\", newline='', encoding=\"utf-8\") as fden:\n",
    "        wden = csv.writer(fden)\n",
    "        wden.writerow([\n",
    "            \"order_id\",\"order_ts\",\"customer_id\",\"customer_name\",\"customer_email\",\"customer_state\",\n",
    "            \"product_id\",\"product_category\",\"qty\",\"unit_price_cents\",\"line_total_cents\",\"payload\"\n",
    "        ])\n",
    "\n",
    "        customers = {}\n",
    "        products = {}\n",
    "        order_id = 0\n",
    "        t0 = datetime(2020, 1, 1)\n",
    "\n",
    "        # gera até atingir o tamanho máximo da desnormalizada\n",
    "        while fden.tell() < target_bytes:\n",
    "            order_id += 1\n",
    "            cust_id = rng.randint(1, n_customers)\n",
    "            cust = customers.setdefault(cust_id, {\n",
    "                \"id\": cust_id,\n",
    "                \"name\": f\"Customer {cust_id}\",\n",
    "                \"email\": f\"c{cust_id}@exemplo.com\",\n",
    "                \"state\": rng.choice(STATES)\n",
    "            })\n",
    "            order_ts = (t0 + timedelta(seconds=rng.randint(0, 60*60*24*365*5))).isoformat()\n",
    "\n",
    "            n_items = max(1, int(rng.gauss(avg_items_per_order, 1.0)))\n",
    "            order_total = 0\n",
    "\n",
    "            for _ in range(n_items):\n",
    "                prod_id = rng.randint(1, n_products)\n",
    "                prod = products.setdefault(prod_id, {\n",
    "                    \"id\": prod_id,\n",
    "                    \"cat\": rng.choice(CATEGORIES),\n",
    "                    \"price\": rng.randint(500, 50_000)\n",
    "                })\n",
    "                qty = max(1, int(rng.expovariate(1/2)))\n",
    "                unit_price = prod[\"price\"]\n",
    "                line_total = unit_price * qty\n",
    "                payload = make_payload(payload_len)\n",
    "                order_total += line_total\n",
    "\n",
    "                wden.writerow([\n",
    "                    order_id, order_ts, cust[\"id\"], cust[\"name\"], cust[\"email\"], cust[\"state\"],\n",
    "                    prod[\"id\"], prod[\"cat\"], qty, unit_price, line_total, payload\n",
    "                ])\n",
    "\n",
    "                append_row(items_p, [order_id, prod[\"id\"], qty, unit_price, line_total, payload])\n",
    "\n",
    "            append_row(orders_p, [order_id, cust[\"id\"], order_ts, order_total])\n",
    "\n",
    "            if order_id % 1000 == 0:\n",
    "                print(f\"[progress] ~{fden.tell()/1024/1024:.1f} MiB escritos (desnormalizada)...\")\n",
    "\n",
    "    for c in customers.values():\n",
    "        append_row(customers_p, [c[\"id\"], c[\"name\"], c[\"email\"], c[\"state\"]])\n",
    "    for p in products.values():\n",
    "        append_row(products_p, [p[\"id\"], p[\"cat\"], p[\"price\"]])\n",
    "\n",
    "    norm_total = sum(p.stat().st_size for p in (customers_p, products_p, orders_p, items_p))\n",
    "    print(f\"Concluído a Normalizada e a Desnormalizada: {out_dir}\")\n",
    "    print(f\" - desnormalizada: {denorm_p.stat().st_size/1024/1024:.8f} MiB\")\n",
    "    print(f\" - normalizada: {norm_total/1024/1024:.8f} MiB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Execução de exemplo ===\n",
    "OUT_DIR = Path(\"dados/base_comparacao_teste\")\n",
    "SIZE_GB = 0.000001\n",
    "CONFIRM_LARGE = True\n",
    "\n",
    "if SIZE_GB >= 1 and not CONFIRM_LARGE:\n",
    "    raise SystemExit(\"Ative CONFIRM_LARGE=True antes de gerar bases >= 1 GiB.\")\n",
    "\n",
    "generate_bases(\n",
    "    OUT_DIR,\n",
    "    target_bytes=int(SIZE_GB * (1024**3)),\n",
    "    seed=42,\n",
    "    n_customers=200_000,\n",
    "    n_products=100_000,\n",
    "    avg_items_per_order=3.0,\n",
    "    payload_len=64\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
